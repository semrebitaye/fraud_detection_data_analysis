{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "fraud_data = pd.read_csv('../data/Fraud_Data.csv')\n",
    "ip_data = pd.read_csv('../data/IpAddress_to_Country.csv')\n",
    "creditcard_data = pd.read_csv('../data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150084</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221365</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151107</th>\n",
       "      <td>345170</td>\n",
       "      <td>2015-01-27 03:03:34</td>\n",
       "      <td>2015-03-29 00:30:47</td>\n",
       "      <td>43</td>\n",
       "      <td>XPSKTWGPWINLR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>28</td>\n",
       "      <td>3.451155e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151108</th>\n",
       "      <td>274471</td>\n",
       "      <td>2015-05-15 17:43:29</td>\n",
       "      <td>2015-05-26 12:24:39</td>\n",
       "      <td>35</td>\n",
       "      <td>LYSFABUCPCGBA</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>2.439047e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151109</th>\n",
       "      <td>368416</td>\n",
       "      <td>2015-03-03 23:07:31</td>\n",
       "      <td>2015-05-20 07:07:47</td>\n",
       "      <td>40</td>\n",
       "      <td>MEQHCSJUBRBFE</td>\n",
       "      <td>SEO</td>\n",
       "      <td>IE</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>2.748471e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151110</th>\n",
       "      <td>207709</td>\n",
       "      <td>2015-07-09 20:06:07</td>\n",
       "      <td>2015-09-07 09:34:46</td>\n",
       "      <td>46</td>\n",
       "      <td>CMCXFGRHYSTVJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>3.601175e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151111</th>\n",
       "      <td>138208</td>\n",
       "      <td>2015-06-10 07:02:20</td>\n",
       "      <td>2015-07-21 02:03:53</td>\n",
       "      <td>20</td>\n",
       "      <td>ZINIADFCLHYPG</td>\n",
       "      <td>Direct</td>\n",
       "      <td>IE</td>\n",
       "      <td>M</td>\n",
       "      <td>38</td>\n",
       "      <td>4.103825e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151112 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0         22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
       "1        333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
       "2          1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
       "3        150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
       "4        221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
       "...         ...                  ...                  ...             ...   \n",
       "151107   345170  2015-01-27 03:03:34  2015-03-29 00:30:47              43   \n",
       "151108   274471  2015-05-15 17:43:29  2015-05-26 12:24:39              35   \n",
       "151109   368416  2015-03-03 23:07:31  2015-05-20 07:07:47              40   \n",
       "151110   207709  2015-07-09 20:06:07  2015-09-07 09:34:46              46   \n",
       "151111   138208  2015-06-10 07:02:20  2015-07-21 02:03:53              20   \n",
       "\n",
       "            device_id  source browser sex  age    ip_address  class  \n",
       "0       QVPSPJUOCKZAR     SEO  Chrome   M   39  7.327584e+08      0  \n",
       "1       EOGFQPIZPYXFZ     Ads  Chrome   F   53  3.503114e+08      0  \n",
       "2       YSSKYOSJHPPLJ     SEO   Opera   M   53  2.621474e+09      1  \n",
       "3       ATGTXKYKUDUQN     SEO  Safari   M   41  3.840542e+09      0  \n",
       "4       NAUITBZFJKHWW     Ads  Safari   M   45  4.155831e+08      0  \n",
       "...               ...     ...     ...  ..  ...           ...    ...  \n",
       "151107  XPSKTWGPWINLR     SEO  Chrome   M   28  3.451155e+09      1  \n",
       "151108  LYSFABUCPCGBA     SEO  Safari   M   32  2.439047e+09      0  \n",
       "151109  MEQHCSJUBRBFE     SEO      IE   F   26  2.748471e+09      0  \n",
       "151110  CMCXFGRHYSTVJ     SEO  Chrome   M   37  3.601175e+09      0  \n",
       "151111  ZINIADFCLHYPG  Direct      IE   M   38  4.103825e+09      0  \n",
       "\n",
       "[151112 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in fraud_data: Index(['user_id', 'signup_time', 'purchase_time', 'purchase_value',\n",
      "       'device_id', 'source', 'browser', 'sex', 'age', 'ip_address', 'class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Inspect columns of fraud_data\n",
    "print(\"Columns in fraud_data:\", fraud_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime strings to datetime objects\n",
    "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
    "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
    "\n",
    "# Extract useful datetime components\n",
    "fraud_data['signup_hour'] = fraud_data['signup_time'].dt.hour\n",
    "fraud_data['signup_day'] = fraud_data['signup_time'].dt.dayofweek\n",
    "fraud_data['purchase_hour'] = fraud_data['purchase_time'].dt.hour\n",
    "fraud_data['purchase_day'] = fraud_data['purchase_time'].dt.dayofweek\n",
    "\n",
    "# Drop the original datetime columns\n",
    "fraud_data = fraud_data.drop(columns=['signup_time', 'purchase_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate Features and Target Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both datasets, separate the features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fraud_data\n",
    "fraud_X = fraud_data.drop(columns=['class'])\n",
    "fraud_y = fraud_data['class']\n",
    "# For creditcard_data\n",
    "creditcard_X = creditcard_data.drop(columns=['Class'])\n",
    "creditcard_y = creditcard_data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Split each dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split fraud_data\n",
    "fraud_X_train, fraud_X_test, fraud_y_train, fraud_y_test = train_test_split(fraud_X, fraud_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split creditcard_data\n",
    "creditcard_X_train, creditcard_X_test, creditcard_y_train, creditcard_y_test = train_test_split(creditcard_X, creditcard_y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing for numerical and categorical features\n",
    "numeric_features = ['purchase_value', 'age']  # Example numeric features\n",
    "categorical_features = ['source', 'browser', 'sex','signup_hour','signup_day', 'purchase_hour', 'purchase_day']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Model Selection and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression, Decision Tree, Random Forest, Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'MLP': MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate models\n",
    "def train_evaluate_model_fraud(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    # Create a pipeline with preprocessing and model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', model)])\n",
    "\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Log metrics with MLflow\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.sklearn.log_model(pipeline, model_name)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_evaluate_model_credit(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    # Create a pipeline with preprocessing and model\n",
    "    pipeline = Pipeline(steps=[('classifier', model)])\n",
    "\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Log metrics with MLflow\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.sklearn.log_model(pipeline, model_name)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semre/fraud_detection_data_analysis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/10/30 09:43:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/30 09:43:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/30 09:45:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/30 09:46:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "/home/semre/fraud_detection_data_analysis/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "2024/10/30 09:48:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models on fraud data\n",
    "fraud_results = []\n",
    "for model_name, model in models.items():\n",
    "    fraud_results.append(train_evaluate_model_fraud(model_name, model, fraud_X_train, fraud_X_test, fraud_y_train, fraud_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semre/fraud_detection_data_analysis/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2024/10/30 10:31:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/30 10:32:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/30 10:36:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/30 10:42:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/30 10:43:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models on credit card data\n",
    "creditcard_results = []\n",
    "for model_name, model in models.items():\n",
    "    creditcard_results.append(train_evaluate_model_credit(model_name, model, creditcard_X_train, creditcard_X_test, creditcard_y_train, creditcard_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Data Results:\n",
      "                  model  accuracy  precision    recall  f1_score\n",
      "0  Logistic Regression  0.906979   0.000000  0.000000  0.000000\n",
      "1        Decision Tree  0.909009   0.509825  0.566042  0.536465\n",
      "2        Random Forest  0.957118   0.994345  0.542092  0.701657\n",
      "3    Gradient Boosting  0.908457   0.935065  0.017074  0.033535\n",
      "4                  MLP  0.947280   0.826834  0.548020  0.659156\n",
      "Credit Card Data Results:\n",
      "                  model  accuracy  precision    recall  f1_score\n",
      "0  Logistic Regression  0.998701   0.589928  0.602941  0.596364\n",
      "1        Decision Tree  0.999111   0.689873  0.801471  0.741497\n",
      "2        Random Forest  0.999625   0.948276  0.808824  0.873016\n",
      "3    Gradient Boosting  0.998584   0.894737  0.125000  0.219355\n",
      "4                  MLP  0.995927   0.259091  0.838235  0.395833\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "fraud_results_df = pd.DataFrame(fraud_results)\n",
    "creditcard_results_df = pd.DataFrame(creditcard_results)\n",
    "\n",
    "print(\"Fraud Data Results:\\n\", fraud_results_df)\n",
    "print(\"Credit Card Data Results:\\n\", creditcard_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
